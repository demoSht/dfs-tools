#!/usr/bin/env python3
"""
Analyse des captures existantes pour extraire les trames Ankama
"""

import os
import sys
import json
import glob
from pathlib import Path
from collections import defaultdict
from unity_decoder import UnityPayloadDecoder

def find_capture_files():
    """Trouve tous les fichiers de capture"""
    capture_patterns = [
        'captures/**/*traffic_data_*.json',
        'captures/**/traffic_data_*.json',
        'traffic_data_*.json',
        '*.json'
    ]

    found_files = []
    for pattern in capture_patterns:
        files = glob.glob(pattern, recursive=True)
        for file in files:
            if 'traffic_data' in file:
                found_files.append(file)

    return found_files

def analyze_captures_for_ankama():
    """Analyse les captures pour extraire les trames Ankama"""
    print("ğŸ” Recherche de captures Dofus...")

    capture_files = find_capture_files()
    if not capture_files:
        print("âŒ Aucun fichier de capture trouvÃ©")
        print("ğŸ’¡ Cherchez des fichiers nommÃ©s 'traffic_data_*.json'")
        return

    print(f"ğŸ“ {len(capture_files)} fichier(s) de capture trouvÃ©(s):")
    for file in capture_files:
        print(f"   â€¢ {file}")

    decoder = UnityPayloadDecoder()

    # Statistiques globales
    total_packets = 0
    ankama_packets = 0
    ankama_frames_count = 0
    frame_types = defaultdict(int)
    all_ankama_data = []

    print(f"\nğŸ” Analyse en cours...")

    for capture_file in capture_files:
        print(f"\nğŸ“„ Traitement: {capture_file}")

        file_packets = 0
        file_ankama_packets = 0
        file_ankama_frames = 0

        try:
            with open(capture_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    try:
                        packet = json.loads(line.strip())
                        total_packets += 1
                        file_packets += 1

                        payload_hex = packet.get('payload_preview', '')
                        if not payload_hex:
                            continue

                        # DÃ©codage avec le dÃ©codeur amÃ©liorÃ©
                        decoded = decoder.decode_payload(payload_hex)

                        # VÃ©rifier les trames Ankama
                        ankama_frames = decoded.get('ankama_frames')
                        if ankama_frames and ankama_frames.get('has_ankama_prefix'):
                            ankama_packets += 1
                            file_ankama_packets += 1

                            parsed_frames = ankama_frames.get('parsed_frames', [])
                            ankama_frames_count += len(parsed_frames)
                            file_ankama_frames += len(parsed_frames)

                            # Collecter les donnÃ©es pour l'analyse
                            for frame in parsed_frames:
                                frame_type = frame.get('classified_type', 'Unknown')
                                frame_types[frame_type] += 1

                                # Sauvegarder les donnÃ©es intÃ©ressantes
                                frame_data = {
                                    'file': capture_file,
                                    'line': line_num,
                                    'timestamp': packet.get('timestamp'),
                                    'frame_type': frame.get('message_type', ''),
                                    'classified_type': frame_type,
                                    'full_type': frame.get('full_type', ''),
                                    'payload_size': frame.get('payload_size', 0),
                                    'source': packet.get('src_ip'),
                                    'destination': packet.get('dst_ip'),
                                    'packet_size': packet.get('size', 0)
                                }

                                # Ajouter le contenu textuel si disponible
                                payload_analysis = frame.get('payload_analysis', {})
                                if 'text_content' in payload_analysis:
                                    text_info = payload_analysis['text_content']
                                    frame_data['text_content'] = text_info.get('text', '')[:200]
                                    frame_data['encoding'] = text_info.get('encoding', '')
                                    frame_data['readability_score'] = text_info.get('readability_score', 0)

                                all_ankama_data.append(frame_data)

                        # Afficher le progrÃ¨s tous les 1000 paquets
                        if file_packets % 1000 == 0:
                            print(f"   ğŸ“¦ {file_packets} paquets traitÃ©s...")

                    except json.JSONDecodeError:
                        continue
                    except Exception as e:
                        continue

            print(f"   âœ… TerminÃ©: {file_packets} paquets, {file_ankama_packets} avec Ankama, {file_ankama_frames} trames")

        except Exception as e:
            print(f"   âŒ Erreur fichier: {e}")

    # Afficher les statistiques finales
    print(f"\nğŸ“Š RÃ‰SULTATS D'ANALYSE")
    print("=" * 50)
    print(f"ğŸ“¦ Total paquets analysÃ©s: {total_packets}")
    print(f"ğŸ¯ Paquets avec trames Ankama: {ankama_packets}")
    print(f"ğŸ“‹ Total trames Ankama extraites: {ankama_frames_count}")

    if ankama_packets > 0:
        print(f"ğŸ“ˆ Taux de trames Ankama: {(ankama_packets/total_packets)*100:.1f}%")

    if frame_types:
        print(f"\nğŸ·ï¸  TYPES DE TRAMES DÃ‰TECTÃ‰ES")
        print("-" * 30)
        sorted_types = sorted(frame_types.items(), key=lambda x: x[1], reverse=True)
        for frame_type, count in sorted_types:
            print(f"   â€¢ {frame_type}: {count} trames")

    # Sauvegarder les rÃ©sultats dÃ©taillÃ©s
    if all_ankama_data:
        output_file = "ankama_frames_analysis.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(all_ankama_data, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ’¾ DonnÃ©es dÃ©taillÃ©es sauvÃ©es: {output_file}")

        # CrÃ©er un rÃ©sumÃ© lisible
        summary_file = "ankama_frames_summary.txt"
        create_readable_summary(all_ankama_data, summary_file)
        print(f"ğŸ“„ RÃ©sumÃ© lisible sauvÃ©: {summary_file}")

        # Afficher quelques exemples
        print(f"\nğŸ“‹ EXEMPLES DE TRAMES DÃ‰TECTÃ‰ES")
        print("-" * 40)

        # Grouper par type pour afficher des exemples variÃ©s
        examples_by_type = defaultdict(list)
        for frame in all_ankama_data:
            frame_type = frame.get('classified_type', 'Unknown')
            examples_by_type[frame_type].append(frame)

        for frame_type, frames in list(examples_by_type.items())[:5]:  # Top 5 types
            print(f"\nğŸ·ï¸  {frame_type} ({len(frames)} total):")
            for frame in frames[:2]:  # 2 exemples max par type
                timestamp = frame.get('timestamp', '').split('T')[1][:8] if frame.get('timestamp') else 'N/A'
                print(f"   [{timestamp}] {frame.get('frame_type', 'unknown')}")
                if 'text_content' in frame:
                    content = frame['text_content'][:60]
                    print(f"      ğŸ’¬ Contenu: '{content}{'...' if len(frame['text_content']) > 60 else ''}'")
                print(f"      ğŸ“ Payload: {frame.get('payload_size', 0)} bytes")

    else:
        print(f"\nâš ï¸  Aucune trame Ankama trouvÃ©e dans les captures")
        print(f"ğŸ’¡ VÃ©rifiez que vos captures contiennent bien du trafic Dofus")

def create_readable_summary(ankama_data, output_file):
    """CrÃ©e un rÃ©sumÃ© lisible des trames Ankama"""
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("ğŸ® ANALYSE DES TRAMES ANKAMA - RÃ‰SUMÃ‰ DÃ‰TAILLÃ‰\n")
        f.write("=" * 60 + "\n\n")

        # Grouper par type
        by_type = defaultdict(list)
        for frame in ankama_data:
            frame_type = frame.get('classified_type', 'Unknown')
            by_type[frame_type].append(frame)

        # Ã‰crire le rÃ©sumÃ© pour chaque type
        for frame_type, frames in sorted(by_type.items()):
            f.write(f"ğŸ·ï¸  {frame_type.upper()} ({len(frames)} trames)\n")
            f.write("-" * 40 + "\n")

            for frame in frames[:10]:  # Limiter Ã  10 exemples par type
                timestamp = frame.get('timestamp', '').split('T')[1][:8] if frame.get('timestamp') else 'N/A'
                f.write(f"[{timestamp}] {frame.get('frame_type', 'unknown')}\n")

                if 'text_content' in frame:
                    content = frame['text_content'][:100]
                    f.write(f"   ğŸ’¬ {content}\n")

                f.write(f"   ğŸ“ {frame.get('payload_size', 0)} bytes | {frame.get('source', 'N/A')} â†’ {frame.get('destination', 'N/A')}\n")
                f.write("\n")

            if len(frames) > 10:
                f.write(f"... et {len(frames) - 10} autres trames de ce type\n")
            f.write("\n")

if __name__ == "__main__":
    try:
        analyze_captures_for_ankama()
        sys.exit(0)
    except KeyboardInterrupt:
        print("\nğŸ›‘ Analyse interrompue par l'utilisateur")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ Erreur: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)